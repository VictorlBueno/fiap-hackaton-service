# Docker Setup - Video Processor

# Infraestrutura Terraform para ECR

Este diret√≥rio cont√©m a configura√ß√£o Terraform para provisionar um reposit√≥rio ECR (Elastic Container Registry) na AWS, utilizado para armazenar as imagens Docker do projeto. A infraestrutura est√° organizada seguindo o padr√£o dos outros projetos.

## Estrutura

```
ecr/
‚îú‚îÄ‚îÄ terraform/           # Configura√ß√µes Terraform
‚îÇ   ‚îú‚îÄ‚îÄ main.tf         # Recursos principais
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf    # Defini√ß√£o de vari√°veis
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf      # Outputs do m√≥dulo
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf    # Configura√ß√£o de providers
‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars # Valores das vari√°veis
‚îú‚îÄ‚îÄ src/                # C√≥digo fonte da aplica√ß√£o
‚îú‚îÄ‚îÄ Dockerfile          # Imagem Docker para produ√ß√£o
‚îú‚îÄ‚îÄ .dockerignore       # Arquivos ignorados no build
‚îú‚îÄ‚îÄ Makefile           # Comandos de automa√ß√£o
‚îî‚îÄ‚îÄ README.md          # Este arquivo
```

## Como usar

1. Configure suas credenciais AWS (ex: via `aws configure` ou vari√°veis de ambiente).
2. Execute os comandos usando o Makefile:
   ```sh
   make tf-init      # Inicializar Terraform
   make tf-plan      # Verificar mudan√ßas
   make tf-apply     # Aplicar mudan√ßas
   make tf-output    # Ver outputs
   ```

## Vari√°veis

As vari√°veis seguem o padr√£o dos outros projetos:
- `aws_region`: Regi√£o AWS (padr√£o: us-east-1)
- `environment`: Ambiente (padr√£o: production)
- `project_name`: Nome do projeto (padr√£o: fiap-hack)
- `force_delete`: Permite deletar reposit√≥rio com imagens (padr√£o: false)

O nome do reposit√≥rio ser√°: `{project_name}-{environment}` (ex: fiap-hack-production)

## üöÄ Deploy ECR

### Deploy Completo
Para fazer deploy completo no ECR:
```bash
make deploy
```

Este comando ir√°:
1. ‚úÖ Verificar pr√©-requisitos (AWS CLI, Docker)
2. üèóÔ∏è Aplicar infraestrutura Terraform (se necess√°rio)
3. üê≥ Build e push da imagem Docker para ECR
4. üìã Orientar sobre deploy no Kubernetes (projeto /service)

### Deploy ECR Apenas
Para fazer deploy apenas no ECR:
```bash
make deploy-ecr
```

### Deploy Infraestrutura
Para aplicar apenas a infraestrutura Terraform:
```bash
make deploy-infra
```

### Pr√©-requisitos para Deploy
- AWS CLI configurado
- Docker instalado e funcionando
- Permiss√µes adequadas na AWS (ECR)

### Fluxo Completo
1. **ECR** (este projeto): `make deploy`
2. **Kubernetes** (projeto /service): `cd ../service && make deploy`

### ‚úÖ Status Atual
- ‚úÖ Reposit√≥rio ECR criado: `fiap-hack-production`
- ‚úÖ URL do ECR: `410211328905.dkr.ecr.us-east-1.amazonaws.com/fiap-hack-production`
- ‚úÖ Imagem Docker buildada e enviada com sucesso
- ‚úÖ Pronto para deploy no Kubernetes

## üöÄ In√≠cio R√°pido

```bash
# Subir todos os servi√ßos
make setup

# Ou manualmente
docker-compose up -d
```

## üìã Servi√ßos

### PostgreSQL
- **Porta**: 5432
- **Database**: video_processor
- **User**: postgres
- **Password**: postgres123

### RabbitMQ
- **AMQP Port**: 5672
- **Management UI**: http://localhost:15672
- **User**: admin
- **Password**: admin123

## üõ†Ô∏è Comandos √öteis

```bash
# Ver todos os comandos dispon√≠veis
make help

# Subir servi√ßos
make up

# Ver logs
make logs

# Conectar no banco
make db-shell

# Abrir RabbitMQ UI
make mq-ui

# Parar tudo
make down

# Limpar volumes
make clean
```

## üîß Configura√ß√£o da Aplica√ß√£o

Certifique-se que o arquivo `.env` est√° configurado:

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=postgres123
DB_NAME=video_processor

# RabbitMQ Configuration
RABBITMQ_URL=amqp://admin:admin123@localhost:5672

# AWS S3 Configuration
AWS_REGION=us-east-1
AWS_S3_BUCKET_NAME=video-processor-bucket

# JWT Configuration
JWT_SECRET=your_jwt_secret_key
```

> **Nota:** Em ambiente AWS Lambda, n√£o √© necess√°rio definir `AWS_ACCESS_KEY_ID` e `AWS_SECRET_ACCESS_KEY`. O Lambda j√° assume uma role IAM com permiss√µes apropriadas automaticamente.

### üì¶ Configura√ß√£o do S3

1. **Crie um bucket S3** na AWS
2. **Configure as permiss√µes da role do Lambda** para permitir upload/download
3. **Configure as vari√°veis** no arquivo `.env` (veja acima)
4. **Copie o arquivo de exemplo**: `cp env.example .env`

## üè• Health Check

```bash
# Verificar se os servi√ßos est√£o funcionando
make health

# Verificar status dos containers
make ps
```

## üìä Monitoramento

- **PostgreSQL**: Use `make db-shell` para conectar
- **RabbitMQ**: Acesse http://localhost:15672 para o painel de controle
- **S3**: Verifique os arquivos no console da AWS S3

## ‚òÅÔ∏è Armazenamento S3

O servi√ßo agora utiliza o Amazon S3 para armazenamento de arquivos:

- **V√≠deos**: S√£o enviados para o S3 ap√≥s upload
- **ZIPs**: Os arquivos ZIP com frames s√£o criados no S3
- **Downloads**: URLs assinadas s√£o geradas para download seguro
- **Limpeza**: Arquivos tempor√°rios s√£o removidos automaticamente

## üßπ Limpeza

```bash
# Limpar pastas tempor√°rias (uploads, outputs, temp)
make cleanup

# Parar e remover tudo (incluindo volumes)
make clean
```

### üìÅ Pastas Tempor√°rias

O projeto usa as seguintes pastas tempor√°rias que s√£o limpas automaticamente:

- **`uploads/`**: Arquivos de v√≠deo tempor√°rios (enviados para S3)
- **`outputs/`**: Arquivos ZIP tempor√°rios (enviados para S3)  
- **`temp/`**: Frames extra√≠dos tempor√°rios (removidos ap√≥s processamento)

> **Nota**: Use `make cleanup` para limpar manualmente essas pastas.

## üîç Solu√ß√£o de Problemas

### PostgreSQL n√£o conecta
```bash
# Verificar logs
make logs-db

# Reiniciar servi√ßo
docker-compose restart postgres
```

### RabbitMQ n√£o conecta
```bash
# Verificar logs
make logs-mq

# Reiniciar servi√ßo
docker-compose restart rabbitmq
```

### Portas em uso
```bash
# Verificar o que est√° usando as portas
lsof -i :5432
lsof -i :5672
lsof -i :15672
```